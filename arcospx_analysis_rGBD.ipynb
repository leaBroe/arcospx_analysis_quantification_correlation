{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:02:07.811797Z",
     "start_time": "2023-11-16T14:02:05.531011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from arcos4py.tools import track_events_image, remove_image_background\n",
    "from arcos4py.tools._detect_events import upscale_image\n",
    "from arcos4py.tools._cleandata import blockwise_median\n",
    "import pandas as pd\n",
    "import napari\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy.ndimage import binary_dilation, binary_fill_holes, binary_erosion\n",
    "from skimage.morphology import erosion, remove_small_objects, square\n",
    "from skimage import io, exposure\n",
    "from scipy import ndimage\n",
    "from skimage.morphology import closing\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def drop_scattered_small_labels(label_image, min_size=100):\n",
    "    \"\"\"\n",
    "    Removes small scattered regions of each label from a labeled image.\n",
    "\n",
    "    Parameters:\n",
    "    - label_image: 2D numpy array representing the labeled image.\n",
    "    - min_size: Minimum pixel size for keeping a scattered part of a label.\n",
    "\n",
    "    Returns:\n",
    "    - Processed image with small scattered labels dropped.\n",
    "    \"\"\"\n",
    "    label_image = closing(label_image)\n",
    "    unique_labels = np.unique(label_image)\n",
    "    output_image = np.zeros_like(label_image)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        if label == 0:  # Assuming 0 is the background\n",
    "            continue\n",
    "\n",
    "        # Create a binary image for the current label\n",
    "        binary_mask = label_image == label\n",
    "\n",
    "        # Identify separate regions of the current label\n",
    "        labeled_mask, num_features = ndimage.label(binary_mask)\n",
    "\n",
    "        # Measure the size of each region\n",
    "        sizes = ndimage.sum(binary_mask, labeled_mask, range(num_features + 1))\n",
    "\n",
    "        # Create a mask of regions to be kept for the current label\n",
    "        mask_size = sizes >= min_size\n",
    "        keep = mask_size[labeled_mask]\n",
    "\n",
    "        # Update the output image with regions of the current label that are kept\n",
    "        output_image[keep] = label\n",
    "\n",
    "    return output_image\n",
    "\n",
    "\n",
    "def process_time_series_label_images(time_series_label_images, min_size=100):\n",
    "    \"\"\"\n",
    "    Processes a time-series of label images by removing small scattered labels.\n",
    "\n",
    "    Parameters:\n",
    "    - time_series_label_images: 3D numpy array representing a time-series of labeled images.\n",
    "      The first dimension is time.\n",
    "    - min_size: Minimum pixel size for keeping a scattered part of a label.\n",
    "\n",
    "    Returns:\n",
    "    - Processed time-series with small scattered labels dropped from each frame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the number of time points\n",
    "    T = time_series_label_images.shape[0]\n",
    "\n",
    "    # Initialize an output array of the same shape as the input\n",
    "    output_images = np.zeros_like(time_series_label_images)\n",
    "\n",
    "    for t in range(T):\n",
    "        output_images[t] = drop_scattered_small_labels(time_series_label_images[t], min_size=min_size)\n",
    "\n",
    "    return output_images\n",
    "\n",
    "\n",
    "def filter_by_centroid_displacement(labeled_stack, min_distance):\n",
    "    \"\"\"\n",
    "    Removes tracks from a labeled image stack if the total displacement of their centroid\n",
    "    is less than the specified minimum distance.\n",
    "    \"\"\"\n",
    "    labeled_stack = np.copy(labeled_stack)\n",
    "\n",
    "    unique_labels = np.unique(labeled_stack)[1:]  # Exclude background (label 0)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Get the coordinates of all pixels belonging to the current label (track) for each time point\n",
    "        time_points = np.unique(np.where(labeled_stack == label)[0])\n",
    "\n",
    "        centroids = []\n",
    "        for t in time_points:\n",
    "            coords = np.argwhere(labeled_stack[t] == label)\n",
    "            centroid = coords.mean(axis=0)\n",
    "            centroids.append(centroid)\n",
    "\n",
    "        # Calculate the total centroid displacement by summing up the distances between consecutive time points\n",
    "        total_distance = sum(np.linalg.norm(centroids[i + 1] - centroids[i]) for i in range(len(centroids) - 1))\n",
    "\n",
    "        # If total displacement is less than min_distance, remove the track\n",
    "        if total_distance < min_distance:\n",
    "            labeled_stack[labeled_stack == label] = 0\n",
    "\n",
    "    return labeled_stack\n",
    "\n",
    "\n",
    "def filter_by_duration(labeled_stack, min_duration):\n",
    "    \"\"\"\n",
    "    Removes tracks from a labeled image stack if their duration is less than the specified minimum.\n",
    "    \"\"\"\n",
    "    labeled_stack = np.copy(labeled_stack)\n",
    "\n",
    "    unique_labels = np.unique(labeled_stack)[1:]  # Exclude background (label 0)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Get the coordinates of all pixels belonging to the current label (track) for each time point\n",
    "        time_points = np.unique(np.where(labeled_stack == label)[0])\n",
    "\n",
    "        # If the duration is less than min_duration, remove the track\n",
    "        if len(time_points) < min_duration:\n",
    "            labeled_stack[labeled_stack == label] = 0\n",
    "\n",
    "    return labeled_stack\n",
    "\n",
    "\n",
    "def smooth_segmentation(binary_objects, expand_iterations=1, remove_small=True, remove_small_objects_size=100):\n",
    "    \"\"\"\n",
    "    Smooths the segmentation by removing small objects and filling holes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    binary_objects : numpy array\n",
    "        Binary image of the segmented objects.\n",
    "    remove_small : bool, optional\n",
    "        Whether to remove small objects. The default is True.\n",
    "    remove_small_objects_size : int, optional\n",
    "        Size of the objects to remove. The default is 100.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    binary_objects : numpy array\n",
    "        Smoothed binary image of the segmented objects.\n",
    "    \"\"\"\n",
    "    binary_objects = np.where(binary_objects == 1, 1, 0)\n",
    "    if len(binary_objects.shape) == 3:\n",
    "        for index, image in enumerate(binary_objects):\n",
    "            image = binary_fill_holes(image)\n",
    "            image = binary_dilation(image, square(5), iterations=expand_iterations)\n",
    "            image = erosion(image, footprint=square(5))\n",
    "            bool_img = image.astype(bool)\n",
    "            if remove_small:\n",
    "                image = remove_small_objects(bool_img, min_size=remove_small_objects_size**2)\n",
    "            image = binary_fill_holes(image)\n",
    "            binary = np.where(image, 1, 0)\n",
    "            binary_objects[index] = binary\n",
    "        return binary_objects\n",
    "    else:\n",
    "        binary_objects = binary_fill_holes(binary_objects)\n",
    "        binary_objects = binary_dilation(binary_objects, square(5), iterations=expand_iterations)\n",
    "        binary_objects = erosion(binary_objects, footprint=square(5))\n",
    "        bool_img = binary_objects.astype(bool)\n",
    "        if remove_small:\n",
    "            binary_objects = remove_small_objects(bool_img, min_size=remove_small_objects_size**2)\n",
    "        binary_objects = binary_fill_holes(binary_objects)\n",
    "        binary_objects = np.where(binary_objects, 1, 0)\n",
    "        return binary_objects\n",
    "\n",
    "def bleach_correction_smooth(img_stack, window_length=11, polyorder=2):\n",
    "    \"\"\"\n",
    "    Perform bleach correction on a t,y,x image stack using Savitzky-Golay smoothing.\n",
    "\n",
    "    Parameters:\n",
    "    - img_stack: 3D numpy array with shape (t, y, x)\n",
    "    - window_length: Length of the filter window (must be odd).\n",
    "    - polyorder: Order of the polynomial used to fit the samples.\n",
    "\n",
    "    Returns:\n",
    "    - Corrected 3D numpy array with same shape as img_stack\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert img_stack to float type for the correction\n",
    "    img_stack = img_stack.astype(np.float64)\n",
    "\n",
    "    # Calculate average intensity for each time point\n",
    "    avg_intensities = img_stack.mean(axis=(1, 2))\n",
    "\n",
    "    # Apply Savitzky-Golay filter to average intensities\n",
    "    smoothed_intensities = savgol_filter(avg_intensities, window_length, polyorder)\n",
    "\n",
    "    # Calculate correction factors\n",
    "    correction_factors = smoothed_intensities / avg_intensities[0]\n",
    "\n",
    "    # Apply correction to the image stack\n",
    "    for i in range(img_stack.shape[0]):\n",
    "        img_stack[i] /= correction_factors[i]\n",
    "\n",
    "    return img_stack\n",
    "\n",
    "\n",
    "def bleach_correction_loess(img_stack, frac=0.1):\n",
    "    \"\"\"\n",
    "    Perform bleach correction on a t,y,x image stack using LOESS smoothing.\n",
    "\n",
    "    Parameters:\n",
    "    - img_stack: 3D numpy array with shape (t, y, x)\n",
    "    - frac: The fraction of data used when estimating each y-value for the lowess fit.\n",
    "            It determines the span of the window; for example, a value of 0.1 means\n",
    "            each smoothed point uses 10% of the data points.\n",
    "\n",
    "    Returns:\n",
    "    - Corrected 3D numpy array with same shape as img_stack\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert img_stack to float type for the correction\n",
    "    img_stack = img_stack.astype(np.float64)\n",
    "\n",
    "    # Calculate average intensity for each time point\n",
    "    avg_intensities = img_stack.mean(axis=(1, 2))\n",
    "\n",
    "    # Time points\n",
    "    t_values = np.arange(len(avg_intensities))\n",
    "\n",
    "    # Apply LOESS smoothing to average intensities\n",
    "    smoothed_intensities = lowess(avg_intensities, t_values, frac=frac, return_sorted=False)\n",
    "\n",
    "    # Calculate correction factors\n",
    "    correction_factors = smoothed_intensities / avg_intensities[0]\n",
    "\n",
    "    # Apply correction to the image stack\n",
    "    for i in range(img_stack.shape[0]):\n",
    "        img_stack[i] /= correction_factors[i]\n",
    "\n",
    "    return img_stack\n",
    "\n",
    "\n",
    "def match_histogram(source, template, bins=65536):\n",
    "    hist_source, bin_edges = np.histogram(source.ravel(), bins=bins, range=(0, bins))\n",
    "    hist_template, _ = np.histogram(template.ravel(), bins=bins, range=(0, bins))\n",
    "\n",
    "    cdf_source = hist_source.cumsum() / hist_source.sum()\n",
    "    cdf_template = hist_template.cumsum() / hist_template.sum()\n",
    "\n",
    "    lookup_table = np.zeros(bins, dtype=np.uint16)\n",
    "    j = 0\n",
    "    for i in range(bins):\n",
    "        while cdf_template[j] < cdf_source[i] and j < bins:\n",
    "            j += 1\n",
    "        lookup_table[i] = j\n",
    "\n",
    "    matched = lookup_table[source]\n",
    "    return matched"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:02:07.826896Z",
     "start_time": "2023-11-16T14:02:07.812326Z"
    }
   },
   "id": "1c92c762c6ff3292"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "stage_2_pos_12 = io.imread(\"transfer_187559_files_94515bab/lifeact_myosin_rgbd7_w15TIRF-GFP_s1_t1.TIF_-_Stage2__Position_12_.tiff\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:02:08.531858Z",
     "start_time": "2023-11-16T14:02:07.827796Z"
    }
   },
   "id": "494c9b2c8db9e682"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/721 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0780d282f7349379203ab3e78bddd08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/721 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37408021a6f34c83b2fbe509f28e3b03"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/721 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d93ee4e5cefb4f6a9b2f4e6b994de86f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "myosin_bl = []\n",
    "rGBD_bl = []\n",
    "actin_bl = []\n",
    "\n",
    "# split up image stack into channels\n",
    "myosin = stage_2_pos_12[..., 0]\n",
    "rGBD = stage_2_pos_12[..., 1]\n",
    "actin = stage_2_pos_12[..., 2]\n",
    "\n",
    "# reference images for histogram matching\n",
    "reference_myosin = myosin[0]\n",
    "reference_rGBD = rGBD[0]\n",
    "reference_actin = actin[0]\n",
    "\n",
    "# perform histogram matching\n",
    "myosin_bl.append(np.stack([match_histogram(img, reference_myosin, bins=100000) for img in tqdm(myosin)]))\n",
    "rGBD_bl.append(np.stack([match_histogram(img, reference_rGBD, bins=100000) for img in tqdm(rGBD)]))\n",
    "actin_bl.append(np.stack([match_histogram(img, reference_actin, bins=100000) for img in tqdm(actin)]))\n",
    "\n",
    "# processed images after histogram matching\n",
    "myosin_bl = np.concatenate(myosin_bl)\n",
    "rGBD_bl = np.concatenate(rGBD_bl)\n",
    "actin_bl = np.concatenate(actin_bl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:03:21.384688Z",
     "start_time": "2023-11-16T14:02:08.534998Z"
    }
   },
   "id": "4f8ea50eec1814c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## rGBD channel after histogram matching"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81d257072ddb554b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Image layer 'rGBD_bl' at 0x7fa71ce3c5b0>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(rGBD)\n",
    "viewer.add_image(rGBD_bl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:03:24.157840Z",
     "start_time": "2023-11-16T14:03:21.385437Z"
    }
   },
   "id": "bd8ecc0524489227"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bin rGBD channel"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c080afa542ba2d1"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 540, 540)\n",
      "(721, 270, 270)\n"
     ]
    }
   ],
   "source": [
    "binned_rGBD = blockwise_median(rGBD, (1, 2, 2))\n",
    "print(rGBD.shape)\n",
    "print(binned_rGBD.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:03:28.438487Z",
     "start_time": "2023-11-16T14:03:24.156607Z"
    }
   },
   "id": "2712b2f16a3954a8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Image layer 'rGBD' at 0x7fa71cb77c40>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(binned_rGBD)\n",
    "viewer.add_image(rGBD)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:03:29.088458Z",
     "start_time": "2023-11-16T14:03:28.438310Z"
    }
   },
   "id": "8c5583c788a3abb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove Background"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b66809c1b155e3a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<Image layer 'rgbd_bg' at 0x7fa65922e980>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgbd_bg = remove_image_background(binned_rGBD, size=(20, 20, 20), filter_type=\"gaussian\")\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(rgbd_bg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:03:38.193085Z",
     "start_time": "2023-11-16T14:03:29.086706Z"
    }
   },
   "id": "546030cf27b2db6f"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 721/721 [01:33<00:00,  7.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Labels layer 'Labels' at 0x7fa66910cd60>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(binned_rGBD)\n",
    "viewer.add_image(rgbd_bg)\n",
    "viewer.add_labels(track_events_image(rgbd_bg > 10, eps=10, minClSz=50, predictor=True, nPrev=2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:48:59.100096Z",
     "start_time": "2023-11-16T14:47:24.715701Z"
    }
   },
   "id": "19ca35dc59de502b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from skimage.morphology import opening\n",
    "from skimage.filters import gaussian"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:07:41.928758Z",
     "start_time": "2023-11-16T14:07:41.920557Z"
    }
   },
   "id": "8e54128b57e1cbe9"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "test = gaussian(opening(rgbd_bg), sigma=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:07:47.903735Z",
     "start_time": "2023-11-16T14:07:44.020725Z"
    }
   },
   "id": "8cb8f37c588c736d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 721/721 [01:09<00:00, 10.43it/s]\n"
     ]
    }
   ],
   "source": [
    "tracked_events_rgbd = track_events_image(test > 10, eps=10, minClSz=50, predictor=True, nPrev=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:08:58.959454Z",
     "start_time": "2023-11-16T14:07:49.652059Z"
    }
   },
   "id": "f870d214c1aa316"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Labels layer 'tracked_events_rgbd' at 0x7fa65c020700>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(test)\n",
    "viewer.add_labels(tracked_events_rgbd)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:47:07.023080Z",
     "start_time": "2023-11-16T14:47:06.341860Z"
    }
   },
   "id": "1ceef231bba69431"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8da1246b39104699"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
