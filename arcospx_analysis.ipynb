{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:42:52.422235Z",
     "start_time": "2023-11-16T14:42:48.991101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from arcos4py.tools import track_events_image, remove_image_background\n",
    "from arcos4py.tools._detect_events import upscale_image\n",
    "from arcos4py.tools._cleandata import blockwise_median\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from napari.viewer import Viewer\n",
    "from skimage import io\n",
    "import napari\n",
    "from scipy.ndimage import distance_transform_edt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:43:01.357649Z",
     "start_time": "2023-11-16T14:43:01.290688Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import binary_dilation, binary_fill_holes, binary_erosion\n",
    "from skimage.morphology import erosion, remove_small_objects, square\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from skimage import io, exposure\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from skimage.morphology import closing\n",
    "\n",
    "import numpy as np\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "\n",
    "def drop_scattered_small_labels(label_image, min_size=100):\n",
    "    \"\"\"\n",
    "    Removes small scattered regions of each label from a labeled image.\n",
    "\n",
    "    Parameters:\n",
    "    - label_image: 2D numpy array representing the labeled image.\n",
    "    - min_size: Minimum pixel size for keeping a scattered part of a label.\n",
    "\n",
    "    Returns:\n",
    "    - Processed image with small scattered labels dropped.\n",
    "    \"\"\"\n",
    "    label_image = closing(label_image)\n",
    "    unique_labels = np.unique(label_image)\n",
    "    output_image = np.zeros_like(label_image)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        if label == 0:  # Assuming 0 is the background\n",
    "            continue\n",
    "\n",
    "        # Create a binary image for the current label\n",
    "        binary_mask = label_image == label\n",
    "\n",
    "        # Identify separate regions of the current label\n",
    "        labeled_mask, num_features = ndimage.label(binary_mask)\n",
    "\n",
    "        # Measure the size of each region\n",
    "        sizes = ndimage.sum(binary_mask, labeled_mask, range(num_features + 1))\n",
    "\n",
    "        # Create a mask of regions to be kept for the current label\n",
    "        mask_size = sizes >= min_size\n",
    "        keep = mask_size[labeled_mask]\n",
    "\n",
    "        # Update the output image with regions of the current label that are kept\n",
    "        output_image[keep] = label\n",
    "\n",
    "    return output_image\n",
    "\n",
    "\n",
    "def process_time_series_label_images(time_series_label_images, min_size=100):\n",
    "    \"\"\"\n",
    "    Processes a time-series of label images by removing small scattered labels.\n",
    "\n",
    "    Parameters:\n",
    "    - time_series_label_images: 3D numpy array representing a time-series of labeled images.\n",
    "      The first dimension is time.\n",
    "    - min_size: Minimum pixel size for keeping a scattered part of a label.\n",
    "\n",
    "    Returns:\n",
    "    - Processed time-series with small scattered labels dropped from each frame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the number of time points\n",
    "    T = time_series_label_images.shape[0]\n",
    "\n",
    "    # Initialize an output array of the same shape as the input\n",
    "    output_images = np.zeros_like(time_series_label_images)\n",
    "\n",
    "    for t in range(T):\n",
    "        output_images[t] = drop_scattered_small_labels(time_series_label_images[t], min_size=min_size)\n",
    "\n",
    "    return output_images\n",
    "\n",
    "\n",
    "def filter_by_centroid_displacement(labeled_stack, min_distance):\n",
    "    \"\"\"\n",
    "    Removes tracks from a labeled image stack if the total displacement of their centroid\n",
    "    is less than the specified minimum distance.\n",
    "    \"\"\"\n",
    "    labeled_stack = np.copy(labeled_stack)\n",
    "\n",
    "    unique_labels = np.unique(labeled_stack)[1:]  # Exclude background (label 0)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Get the coordinates of all pixels belonging to the current label (track) for each time point\n",
    "        time_points = np.unique(np.where(labeled_stack == label)[0])\n",
    "\n",
    "        centroids = []\n",
    "        for t in time_points:\n",
    "            coords = np.argwhere(labeled_stack[t] == label)\n",
    "            centroid = coords.mean(axis=0)\n",
    "            centroids.append(centroid)\n",
    "\n",
    "        # Calculate the total centroid displacement by summing up the distances between consecutive time points\n",
    "        total_distance = sum(np.linalg.norm(centroids[i + 1] - centroids[i]) for i in range(len(centroids) - 1))\n",
    "\n",
    "        # If total displacement is less than min_distance, remove the track\n",
    "        if total_distance < min_distance:\n",
    "            labeled_stack[labeled_stack == label] = 0\n",
    "\n",
    "    return labeled_stack\n",
    "\n",
    "\n",
    "def filter_by_duration(labeled_stack, min_duration):\n",
    "    \"\"\"\n",
    "    Removes tracks from a labeled image stack if their duration is less than the specified minimum.\n",
    "    \"\"\"\n",
    "    labeled_stack = np.copy(labeled_stack)\n",
    "\n",
    "    unique_labels = np.unique(labeled_stack)[1:]  # Exclude background (label 0)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Get the coordinates of all pixels belonging to the current label (track) for each time point\n",
    "        time_points = np.unique(np.where(labeled_stack == label)[0])\n",
    "\n",
    "        # If the duration is less than min_duration, remove the track\n",
    "        if len(time_points) < min_duration:\n",
    "            labeled_stack[labeled_stack == label] = 0\n",
    "\n",
    "    return labeled_stack\n",
    "\n",
    "\n",
    "def smooth_segmentation(binary_objects, expand_iterations=1, remove_small=True, remove_small_objects_size=100):\n",
    "    \"\"\"\n",
    "    Smooths the segmentation by removing small objects and filling holes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    binary_objects : numpy array\n",
    "        Binary image of the segmented objects.\n",
    "    remove_small : bool, optional\n",
    "        Whether to remove small objects. The default is True.\n",
    "    remove_small_objects_size : int, optional\n",
    "        Size of the objects to remove. The default is 100.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    binary_objects : numpy array\n",
    "        Smoothed binary image of the segmented objects.\n",
    "    \"\"\"\n",
    "    binary_objects = np.where(binary_objects == 1, 1, 0)\n",
    "    if len(binary_objects.shape) == 3:\n",
    "        for index, image in enumerate(binary_objects):\n",
    "            image = binary_fill_holes(image)\n",
    "            image = binary_dilation(image, square(5), iterations=expand_iterations)\n",
    "            image = erosion(image, footprint=square(5))\n",
    "            bool_img = image.astype(bool)\n",
    "            if remove_small:\n",
    "                image = remove_small_objects(bool_img, min_size=remove_small_objects_size**2)\n",
    "            image = binary_fill_holes(image)\n",
    "            binary = np.where(image, 1, 0)\n",
    "            binary_objects[index] = binary\n",
    "        return binary_objects\n",
    "    else:\n",
    "        binary_objects = binary_fill_holes(binary_objects)\n",
    "        binary_objects = binary_dilation(binary_objects, square(5), iterations=expand_iterations)\n",
    "        binary_objects = erosion(binary_objects, footprint=square(5))\n",
    "        bool_img = binary_objects.astype(bool)\n",
    "        if remove_small:\n",
    "            binary_objects = remove_small_objects(bool_img, min_size=remove_small_objects_size**2)\n",
    "        binary_objects = binary_fill_holes(binary_objects)\n",
    "        binary_objects = np.where(binary_objects, 1, 0)\n",
    "        return binary_objects\n",
    "\n",
    "def bleach_correction_smooth(img_stack, window_length=11, polyorder=2):\n",
    "    \"\"\"\n",
    "    Perform bleach correction on a t,y,x image stack using Savitzky-Golay smoothing.\n",
    "\n",
    "    Parameters:\n",
    "    - img_stack: 3D numpy array with shape (t, y, x)\n",
    "    - window_length: Length of the filter window (must be odd).\n",
    "    - polyorder: Order of the polynomial used to fit the samples.\n",
    "\n",
    "    Returns:\n",
    "    - Corrected 3D numpy array with same shape as img_stack\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert img_stack to float type for the correction\n",
    "    img_stack = img_stack.astype(np.float64)\n",
    "\n",
    "    # Calculate average intensity for each time point\n",
    "    avg_intensities = img_stack.mean(axis=(1, 2))\n",
    "\n",
    "    # Apply Savitzky-Golay filter to average intensities\n",
    "    smoothed_intensities = savgol_filter(avg_intensities, window_length, polyorder)\n",
    "\n",
    "    # Calculate correction factors\n",
    "    correction_factors = smoothed_intensities / avg_intensities[0]\n",
    "\n",
    "    # Apply correction to the image stack\n",
    "    for i in range(img_stack.shape[0]):\n",
    "        img_stack[i] /= correction_factors[i]\n",
    "\n",
    "    return img_stack\n",
    "\n",
    "\n",
    "def bleach_correction_loess(img_stack, frac=0.1):\n",
    "    \"\"\"\n",
    "    Perform bleach correction on a t,y,x image stack using LOESS smoothing.\n",
    "\n",
    "    Parameters:\n",
    "    - img_stack: 3D numpy array with shape (t, y, x)\n",
    "    - frac: The fraction of data used when estimating each y-value for the lowess fit.\n",
    "            It determines the span of the window; for example, a value of 0.1 means\n",
    "            each smoothed point uses 10% of the data points.\n",
    "\n",
    "    Returns:\n",
    "    - Corrected 3D numpy array with same shape as img_stack\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert img_stack to float type for the correction\n",
    "    img_stack = img_stack.astype(np.float64)\n",
    "\n",
    "    # Calculate average intensity for each time point\n",
    "    avg_intensities = img_stack.mean(axis=(1, 2))\n",
    "\n",
    "    # Time points\n",
    "    t_values = np.arange(len(avg_intensities))\n",
    "\n",
    "    # Apply LOESS smoothing to average intensities\n",
    "    smoothed_intensities = lowess(avg_intensities, t_values, frac=frac, return_sorted=False)\n",
    "\n",
    "    # Calculate correction factors\n",
    "    correction_factors = smoothed_intensities / avg_intensities[0]\n",
    "\n",
    "    # Apply correction to the image stack\n",
    "    for i in range(img_stack.shape[0]):\n",
    "        img_stack[i] /= correction_factors[i]\n",
    "\n",
    "    return img_stack\n",
    "\n",
    "\n",
    "def match_histogram(source, template, bins=65536):\n",
    "    hist_source, bin_edges = np.histogram(source.ravel(), bins=bins, range=(0, bins))\n",
    "    hist_template, _ = np.histogram(template.ravel(), bins=bins, range=(0, bins))\n",
    "\n",
    "    cdf_source = hist_source.cumsum() / hist_source.sum()\n",
    "    cdf_template = hist_template.cumsum() / hist_template.sum()\n",
    "\n",
    "    lookup_table = np.zeros(bins, dtype=np.uint16)\n",
    "    j = 0\n",
    "    for i in range(bins):\n",
    "        while cdf_template[j] < cdf_source[i] and j < bins:\n",
    "            j += 1\n",
    "        lookup_table[i] = j\n",
    "\n",
    "    matched = lookup_table[source]\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:43:04.913087Z",
     "start_time": "2023-11-16T14:43:03.128039Z"
    }
   },
   "outputs": [],
   "source": [
    "stage_2_pos_12 = io.imread(\"transfer_187559_files_94515bab/lifeact_myosin_rgbd7_w15TIRF-GFP_s1_t1.TIF_-_Stage2__Position_12_.tiff\")\n",
    "# stable_fibres = io.imread(\"Cell1-stable-fibres.tif\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:43:06.526221Z",
     "start_time": "2023-11-16T14:43:06.511098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(721, 540, 540, 3)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_2_pos_12.shape\n",
    "# 721 timepoints\n",
    "# 512x512 pixels\n",
    "# 3 channels (myosin, rGBD, actin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:44:29.392814Z",
     "start_time": "2023-11-16T14:43:19.278218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/721 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7750415f200a4125983dc91ab720c6c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/721 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "779da6f3095d4f058e68e93914fb9556"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/721 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd0fd963b51344db8d9ce39bb10738dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "myosin_bl = []\n",
    "rGBD_bl = []\n",
    "actin_bl = []\n",
    "\n",
    "# split up image stack into channels\n",
    "myosin = stage_2_pos_12[..., 0]\n",
    "rGBD = stage_2_pos_12[..., 1]\n",
    "actin = stage_2_pos_12[..., 2]\n",
    "\n",
    "# reference images for histogram matching\n",
    "reference_myosin = myosin[0]\n",
    "reference_rGBD = rGBD[0]\n",
    "reference_actin = actin[0]\n",
    "\n",
    "# perform histogram matching\n",
    "myosin_bl.append(np.stack([match_histogram(img, reference_myosin, bins=100000) for img in tqdm(myosin)]))\n",
    "rGBD_bl.append(np.stack([match_histogram(img, reference_rGBD, bins=100000) for img in tqdm(rGBD)]))\n",
    "actin_bl.append(np.stack([match_histogram(img, reference_actin, bins=100000) for img in tqdm(actin)]))\n",
    "\n",
    "# processed images after histogram matching\n",
    "myosin_bl = np.concatenate(myosin_bl)\n",
    "rGBD_bl = np.concatenate(rGBD_bl)\n",
    "actin_bl = np.concatenate(actin_bl)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Myosin Channel + after Histogram Matching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Image layer 'myosin_bl' at 0x7fb0b6c2edd0>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(myosin)\n",
    "viewer.add_image(myosin_bl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:44:34.144211Z",
     "start_time": "2023-11-16T14:44:31.252821Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# rGBD Channel + after Histogram Matching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Image layer 'rGBD_bl' at 0x7fc69781f730>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(rGBD)\n",
    "viewer.add_image(rGBD_bl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T13:34:11.549058Z",
     "start_time": "2023-11-16T13:34:10.857324Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Actin Channel + after Histogram Matching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Image layer 'actin_bl' at 0x7fc5ca48ac80>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(actin)\n",
    "viewer.add_image(actin_bl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T13:34:12.177117Z",
     "start_time": "2023-11-16T13:34:11.555481Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Edge detection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'images' is your 3D array with shape (721, 540, 540)\n",
    "edges_detected = np.zeros_like(myosin)  # Create an array to store the edges\n",
    "\n",
    "for i in range(myosin.shape[0]):  # Iterate through each slice\n",
    "    slice = myosin[i, :, :]  # Get the ith slice\n",
    "    \n",
    "    # Convert the slice to 8-bit if it's not already, as Canny requires 8-bit input\n",
    "    if slice.dtype != np.uint8:\n",
    "        # Normalize the image data to 0 - 255\n",
    "        slice_normalized = cv2.normalize(slice, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        # Convert to 8-bit\n",
    "        slice_8bit = np.uint8(slice_normalized)\n",
    "    else:\n",
    "        slice_8bit = slice\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(slice_8bit, threshold1=500, threshold2=600)\n",
    "    \n",
    "    # Store the edges in the corresponding position in the edges_detected array\n",
    "    edges_detected[i, :, :] = edges\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T13:34:12.802615Z",
     "start_time": "2023-11-16T13:34:12.179539Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<Image layer 'myosin' at 0x7fc5cca75e10>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(edges_detected)\n",
    "viewer.add_image(myosin)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T13:34:13.562489Z",
     "start_time": "2023-11-16T13:34:12.807601Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bin myosin channel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 540, 540)\n",
      "(721, 180, 180)\n"
     ]
    }
   ],
   "source": [
    "binned_myosin = blockwise_median(myosin, (1, 3, 3))\n",
    "\n",
    "print(myosin.shape)\n",
    "print(binned_myosin.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T13:34:16.431108Z",
     "start_time": "2023-11-16T13:34:13.563380Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<Image layer 'myosin' at 0x7fc6001d3670>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(binned_myosin)\n",
    "viewer.add_image(myosin)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:41:41.193571Z",
     "start_time": "2023-11-16T14:41:40.549599Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T13:34:19.972580Z",
     "start_time": "2023-11-16T13:34:17.113424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(721, 180, 180)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binned_actin = blockwise_median(actin_bl, (1, 3, 3))\n",
    "binned_actin.shape\n",
    "# io.imsave(\"binned_actin.tif\", binned_actin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:40:41.196212Z",
     "start_time": "2023-11-16T14:40:38.007655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Image layer 'actin_bl' at 0x7fc6978dc880>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(binned_actin)\n",
    "viewer.add_image(actin_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T13:34:25.082224Z",
     "start_time": "2023-11-16T13:34:20.781325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Image layer 'myosin_bg' at 0x7fc5ccc59210>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myosin_bg = remove_image_background(binned_myosin, size=(20, 20, 20), filter_type=\"gaussian\")\n",
    "#actin_bg = np.where(actin_bg < 0, 0, actin_bg)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(myosin_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T13:35:13.353185Z",
     "start_time": "2023-11-16T13:34:25.087538Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 721/721 [00:47<00:00, 15.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Labels layer 'Labels' at 0x7fc5e89db280>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(binned_myosin)\n",
    "viewer.add_image(myosin_bg)\n",
    "viewer.add_labels(track_events_image(myosin_bg > 10, eps=10, minClSz=50, predictor=True, nPrev=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from skimage.morphology import opening\n",
    "from skimage.filters import gaussian\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T13:35:13.355064Z",
     "start_time": "2023-11-16T13:35:13.351712Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T13:35:15.037257Z",
     "start_time": "2023-11-16T13:35:13.355867Z"
    }
   },
   "outputs": [],
   "source": [
    "test = gaussian(opening(myosin_bg), sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T13:35:55.698656Z",
     "start_time": "2023-11-16T13:35:15.037693Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 721/721 [00:40<00:00, 17.75it/s]\n"
     ]
    }
   ],
   "source": [
    "tracked_events = track_events_image(test > 10, eps=10, minClSz=50, predictor=True, nPrev=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<Labels layer 'tracked_events' at 0x7fc5d08b0e20>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(test)\n",
    "viewer.add_image(binned_myosin)\n",
    "viewer.add_labels(tracked_events)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T13:35:56.927758Z",
     "start_time": "2023-11-16T13:35:55.701140Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do seg with convpaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T13:38:10.519293Z",
     "start_time": "2023-11-16T13:38:07.240998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Image layer 'binned_myosin' at 0x7fc673198790>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(binned_myosin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T13:35:58.650497Z",
     "start_time": "2023-11-16T13:35:57.627435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Labels layer 'tracked_events' at 0x7fc5e9e2be50>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(test)\n",
    "viewer.add_image(myosin_bg)\n",
    "viewer.add_labels(tracked_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Smoothed Segmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T13:36:02.619253Z",
     "start_time": "2023-11-16T13:35:58.655629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Labels layer 'smoothened' at 0x7fc5ea90c7c0>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_labels(tracked_events)\n",
    "# seg_smoothed = smooth_segmentation(viewer.layers[\"events_1\"].data, expand_iterations=1, remove_small_objects_size=50, remove_small=False)\n",
    "smoothened = smooth_segmentation(tracked_events, expand_iterations=1, remove_small_objects_size=50, remove_small=False)\n",
    "\n",
    "viewer.add_labels(smoothened, name=\"smoothened\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distance Transformation: Not working yet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T13:36:03.152612Z",
     "start_time": "2023-11-16T13:36:02.618964Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seg_smoothed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m dist_transform \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[43mseg_smoothed\u001B[49m:\n\u001B[1;32m      3\u001B[0m     dist_transform\u001B[38;5;241m.\u001B[39mappend(distance_transform_edt(i)\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint16))\n\u001B[1;32m      5\u001B[0m dist_transform \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mstack(dist_transform)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'seg_smoothed' is not defined"
     ]
    }
   ],
   "source": [
    "dist_transform = []\n",
    "for i in seg_smoothed:\n",
    "    dist_transform.append(distance_transform_edt(i).astype(np.uint16))\n",
    "\n",
    "dist_transform = np.stack(dist_transform)\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(dist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T13:36:03.154832Z",
     "start_time": "2023-11-16T13:36:03.154215Z"
    }
   },
   "outputs": [],
   "source": [
    "# targeting elements that are either very close to or very far from the nearest edge?\n",
    "test_no_edge = np.where((dist_transform < 15) | (dist_transform > 50), 0, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.156583Z"
    }
   },
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(test_no_edge, name=\"test_no_edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.159128Z"
    }
   },
   "outputs": [],
   "source": [
    "events_1 = track_events_image(test_no_edge > 1, eps=5, minClSz=15, predictor=True, nPrev=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.161407Z"
    }
   },
   "outputs": [],
   "source": [
    "events_1_filtered = process_time_series_label_images(events_1, 5)\n",
    "events_1_filtered = filter_by_duration(events_1_filtered, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.163593Z"
    }
   },
   "outputs": [],
   "source": [
    "viewer = napari.current_viewer()\n",
    "viewer.add_labels(events_1, name=\"events_1\")\n",
    "viewer.add_labels(events_1_filtered, name=\"events_1_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.166044Z"
    }
   },
   "outputs": [],
   "source": [
    "events_1 = track_events_image(test > 10, eps=10, minClSz=50, predictor=True, nPrev=2)\n",
    "\n",
    "events_upscaled = []\n",
    "for t in events_1:\n",
    "    t_img = upscale_image(t, 3)\n",
    "    events_upscaled.append(t_img)\n",
    "\n",
    "events_upscaled = np.stack(events_upscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.168951Z"
    }
   },
   "outputs": [],
   "source": [
    "#events_1 = track_events_image(test > 10, eps=10, minClSz=50, predictor=True, nPrev=2)\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(myosin, name=\"myosin\")\n",
    "viewer.add_labels(events_upscaled, name=\"events_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.171204Z"
    }
   },
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(myosin, name=\"myosin\")\n",
    "viewer.add_labels(events_upscaled, name=\"events_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.174012Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops_table\n",
    "\n",
    "df_all = []\n",
    "for idx, e in enumerate(events_upscaled):\n",
    "    props = regionprops_table(e, properties=(\"label\", \"area\", \"centroid\", 'intensity_mean'), intensity_image=actin[idx][:, :1160])\n",
    "    df_temp = pd.DataFrame(props)\n",
    "    df_temp[\"frame\"] = idx * 30\n",
    "    df_all.append(df_temp)\n",
    "\n",
    "df_all = pd.concat(df_all)\n",
    "\n",
    "df_all.rename(columns={\"centroid-0\": \"x\", \"centroid-1\": \"y\", \"label\": \"id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.177611Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.182428Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_summary_statistics(df):\n",
    "    # Initializing lists to hold statistics for all objects\n",
    "    obj_ids = []\n",
    "    origin_x = []\n",
    "    origin_y = []\n",
    "    origin_t = []\n",
    "    end_x = []\n",
    "    end_y = []\n",
    "    end_t = []\n",
    "    lifetimes = []\n",
    "    avg_sizes = []\n",
    "    avg_velocities = []\n",
    "    persistences = []\n",
    "\n",
    "    for obj_id in df[\"id\"].unique():\n",
    "        obj_df = df[df[\"id\"] == obj_id].sort_values(by=\"frame\")\n",
    "\n",
    "        # Origin and End points\n",
    "        origin_x.append(obj_df.iloc[0][\"x\"])\n",
    "        origin_y.append(obj_df.iloc[0][\"y\"])\n",
    "        origin_t.append(obj_df.iloc[0][\"frame\"])\n",
    "        end_x.append(obj_df.iloc[-1][\"x\"])\n",
    "        end_y.append(obj_df.iloc[-1][\"y\"])\n",
    "        end_t.append(obj_df.iloc[-1][\"frame\"])\n",
    "\n",
    "        # Lifetime\n",
    "        lifetime = obj_df[\"frame\"].max() - obj_df[\"frame\"].min() + 1\n",
    "        lifetimes.append(lifetime)\n",
    "\n",
    "        # Average size\n",
    "        avg_sizes.append(obj_df[\"area\"].mean())\n",
    "\n",
    "        # Average velocity\n",
    "        obj_df[\"dx\"] = obj_df[\"x\"].diff()\n",
    "        obj_df[\"dy\"] = obj_df[\"y\"].diff()\n",
    "        obj_df[\"dt\"] = obj_df[\"frame\"].diff()\n",
    "        velocities = np.sqrt(obj_df[\"dx\"] ** 2 + obj_df[\"dy\"] ** 2) / obj_df[\"dt\"]\n",
    "        avg_velocities.append(velocities.mean())\n",
    "\n",
    "        # Persistence\n",
    "        net_displacement = np.linalg.norm(\n",
    "            [obj_df[\"x\"].iloc[-1] - obj_df[\"x\"].iloc[0], obj_df[\"y\"].iloc[-1] - obj_df[\"y\"].iloc[0]]\n",
    "        )\n",
    "        total_distance = np.sum(np.sqrt(obj_df[\"x\"].diff() ** 2 + obj_df[\"y\"].diff() ** 2))\n",
    "        persistence = net_displacement / total_distance if total_distance != 0 else 0  # To avoid division by zero\n",
    "        persistences.append(persistence)\n",
    "\n",
    "        # Add to object IDs list\n",
    "        obj_ids.append(obj_id)\n",
    "\n",
    "    # Creating the summary DataFrame\n",
    "    summary_df = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": obj_ids,\n",
    "            \"origin_x\": origin_x,\n",
    "            \"origin_y\": origin_y,\n",
    "            \"origin_t\": origin_t,\n",
    "            \"end_x\": end_x,\n",
    "            \"end_y\": end_y,\n",
    "            \"end_t\": end_t,\n",
    "            \"lifetime\": lifetimes,\n",
    "            \"avg_size\": avg_sizes,\n",
    "            \"avg_velocity\": avg_velocities,\n",
    "            \"persistence\": persistences,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "summary_df = get_summary_statistics(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.186121Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(5, 5), sharex=False)\n",
    "\n",
    "axs = axs.flatten()\n",
    "axs[0].hist(summary_df[\"lifetime\"], bins=10)\n",
    "axs[0].set_title(\"Lifetime [s]\")\n",
    "\n",
    "axs[1].hist(summary_df[\"avg_size\"], bins=10)\n",
    "axs[1].set_title(\"Average Size [px]\")\n",
    "\n",
    "axs[2].hist(summary_df[\"avg_velocity\"], bins=10)\n",
    "axs[2].set_title(\"Average Centorid Velocity \\n [px/s]\")\n",
    "\n",
    "axs[3].hist(summary_df[\"persistence\"], bins=10)\n",
    "axs[3].set_title(\"Persistence [ratio]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(\"summary_stats_fibers.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.189431Z"
    }
   },
   "outputs": [],
   "source": [
    "summary_df.persistence.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.193867Z"
    }
   },
   "outputs": [],
   "source": [
    "# add origin and end points to to napari at their respective frames\n",
    "viewer = napari.current_viewer()\n",
    "viewer.add_points(\n",
    "    summary_df[[\"origin_t\", \"origin_x\", \"origin_y\"]].values,\n",
    "    name=\"origin\",\n",
    "    face_color=\"red\",\n",
    "    symbol=\"cross\",\n",
    "    size=30,\n",
    "    n_dimensional=True,\n",
    ")\n",
    "viewer.add_points(\n",
    "    summary_df[[\"end_t\", \"end_x\", \"end_y\"]].values,\n",
    "    name=\"end\",\n",
    "    face_color=\"blue\",\n",
    "    symbol=\"cross\",\n",
    "    size=30,\n",
    "    n_dimensional=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.197035Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "class CameraSetter:\n",
    "    \"\"\"A context manager to adjust viewer camera settings before rendering.\"\"\"\n",
    "\n",
    "    def __init__(self, viewer):\n",
    "        self.viewer = viewer\n",
    "        # get initial settings\n",
    "        self.center = viewer.camera.center\n",
    "        self.zoom = viewer.camera.zoom\n",
    "        self.angles = viewer.camera.angles\n",
    "\n",
    "        self.input_canvas_size = viewer.window.qt_viewer.canvas.size\n",
    "\n",
    "        extent = viewer._sliced_extent_world[:, -2:]\n",
    "        scene_size = (extent[1] - extent[0]) / viewer.window.qt_viewer.canvas.pixel_scale  # adjust for pixel scaling\n",
    "        grid_size = list(viewer.grid.actual_shape(len(viewer.layers)))\n",
    "\n",
    "        # Adjust grid_size if necessary\n",
    "        if len(scene_size) > len(grid_size):\n",
    "            grid_size = [1] * (len(scene_size) - len(grid_size)) + grid_size\n",
    "\n",
    "        # calculate target size i.e the size the canvas should be to fit the whole scene\n",
    "        self.target_size = tuple((scene_size[::-1] / 2 * grid_size[::-1]).astype(int))\n",
    "        self.center = viewer.camera.center\n",
    "        self.zoom = viewer.camera.zoom\n",
    "        self.angles = viewer.camera.angles\n",
    "\n",
    "    # copied from viewer.reset_view and modified without padding\n",
    "    def _center_on_canvas(self):\n",
    "        \"\"\"Reset the camera view.\"\"\"\n",
    "        extent = self.viewer._sliced_extent_world\n",
    "        scene_size = extent[1] - extent[0]\n",
    "        corner = extent[0]\n",
    "        grid_size = list(self.viewer.grid.actual_shape(len(self.viewer.layers)))\n",
    "        if len(scene_size) > len(grid_size):\n",
    "            grid_size = [1] * (len(scene_size) - len(grid_size)) + grid_size\n",
    "        size = np.multiply(scene_size, grid_size)\n",
    "        center = np.add(corner, np.divide(size, 2))[-self.viewer.dims.ndisplay :]\n",
    "        center = [0] * (self.viewer.dims.ndisplay - len(center)) + list(center)\n",
    "        self.viewer.camera.center = center\n",
    "\n",
    "        if np.max(size) == 0:\n",
    "            self.viewer.camera.zoom = np.min(self.viewer._canvas_size)\n",
    "        else:\n",
    "            scale = np.array(size[-2:])\n",
    "            scale[np.isclose(scale, 0)] = 1\n",
    "            self.viewer.camera.zoom = 1 * np.min(np.array(self.viewer._canvas_size) / scale)\n",
    "        self.viewer.camera.angles = (0, 0, 90)\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Set up the viewer for rendering.\"\"\"\n",
    "        self.viewer.window.qt_viewer.canvas.size = self.target_size\n",
    "        self._center_on_canvas()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Reset the viewer after rendering.\"\"\"\n",
    "        self.viewer.window.qt_viewer.canvas.size = self.input_canvas_size\n",
    "        self.viewer.camera.center = self.center\n",
    "        self.viewer.camera.zoom = self.zoom\n",
    "        self.viewer.camera.angles = self.angles\n",
    "\n",
    "\n",
    "def render_as_rgb(viewer, axis: None | int = None):\n",
    "    \"\"\"Render the viewer for a single timepoint.\"\"\"\n",
    "    with CameraSetter(viewer):\n",
    "        if axis is not None:\n",
    "            rgb = []\n",
    "            for i in range(viewer.dims.range[axis][1].astype(int)):\n",
    "                viewer.dims.set_current_step(axis, i)\n",
    "                rendered_img = viewer.window.qt_viewer.canvas.render(alpha=False)\n",
    "                rgb.append(rendered_img)\n",
    "            rendered_img = np.stack(rgb)\n",
    "        else:\n",
    "            rendered_img = viewer.window.qt_viewer.canvas.render(alpha=False)\n",
    "    return rendered_img\n",
    "\n",
    "\n",
    "# Usage\n",
    "rgb = []\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    rendered_img = render_as_rgb(viewer, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.199958Z"
    }
   },
   "outputs": [],
   "source": [
    "events_filtered = remove_short_lived_labels(events_1)\n",
    "viewer.add_labels(events_filtered, name=\"events_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.202912Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Read the first image to get the width, height\n",
    "frame = rendered_img[0]\n",
    "h, w, layers = frame.shape\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\"origin_end_waves_stable.mp4\", fourcc, 12, (w, h))\n",
    "\n",
    "for image in rendered_img:\n",
    "    out.write(cv2.cvtColor(image, cv2.COLOR_RGBA2BGR))  # Write out frame to video\n",
    "\n",
    "# Release everything when the job is finished\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T13:36:03.210484Z",
     "start_time": "2023-11-16T13:36:03.204383Z"
    }
   },
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(actin, colormap=\"gray_r\", name=\"actin\")\n",
    "viewer.add_image(myosin, colormap=\"gray_r\", name=\"myosin\")\n",
    "viewer.add_image(rGBD, colormap=\"gray_r\", name=\"rGBD\")\n",
    "viewer.add_labels(events_upscaled, name=\"events_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.205891Z"
    }
   },
   "outputs": [],
   "source": [
    "io.imshow(rendered_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.207036Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import napari\n",
    "import numpy as np\n",
    "import warnings\n",
    "from skimage import io\n",
    "from magicgui import magicgui\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "class CameraSetter:\n",
    "    \"\"\"A context manager to adjust viewer camera settings before rendering.\"\"\"\n",
    "\n",
    "    def __init__(self, viewer, upsample_factor=1):\n",
    "        self.viewer = viewer\n",
    "        # get initial settings\n",
    "        self.center = viewer.camera.center\n",
    "        self.zoom = viewer.camera.zoom\n",
    "        self.angles = viewer.camera.angles\n",
    "\n",
    "        self.input_canvas_size = viewer.window.qt_viewer.canvas.size\n",
    "\n",
    "        extent = viewer._sliced_extent_world[:, -2:]\n",
    "        scene_size = (extent[1] - extent[0]) / viewer.window.qt_viewer.canvas.pixel_scale * upsample_factor # adjust for pixel scaling\n",
    "        grid_size = list(viewer.grid.actual_shape(len(viewer.layers)))\n",
    "\n",
    "        # Adjust grid_size if necessary\n",
    "        if len(scene_size) > len(grid_size):\n",
    "            grid_size = [1] * (len(scene_size) - len(grid_size)) + grid_size\n",
    "\n",
    "        # calculate target size i.e the size the canvas should be to fit the whole scene\n",
    "        self.target_size = tuple((scene_size[::-1] * grid_size[::-1]).astype(int))\n",
    "        self.center = viewer.camera.center\n",
    "        self.zoom = viewer.camera.zoom\n",
    "        self.angles = viewer.camera.angles\n",
    "\n",
    "    # copied from viewer.reset_view and modified without padding\n",
    "    def _center_on_canvas(self):\n",
    "        \"\"\"Reset the camera view.\"\"\"\n",
    "        extent = self.viewer._sliced_extent_world\n",
    "        scene_size = extent[1] - extent[0]\n",
    "        corner = extent[0]\n",
    "        grid_size = list(self.viewer.grid.actual_shape(len(self.viewer.layers)))\n",
    "        if len(scene_size) > len(grid_size):\n",
    "            grid_size = [1] * (len(scene_size) - len(grid_size)) + grid_size\n",
    "        size = np.multiply(scene_size, grid_size)\n",
    "        center = np.add(corner, np.divide(size, 2))[-self.viewer.dims.ndisplay :]\n",
    "        center = [0] * (self.viewer.dims.ndisplay - len(center)) + list(center)\n",
    "        self.viewer.camera.center = center\n",
    "\n",
    "        if np.max(size) == 0:\n",
    "            self.viewer.camera.zoom = np.min(self.viewer._canvas_size)\n",
    "        else:\n",
    "            scale = np.array(size[-2:])\n",
    "            scale[np.isclose(scale, 0)] = 1\n",
    "            self.viewer.camera.zoom = 1 * np.min(np.array(self.viewer._canvas_size) / scale)\n",
    "        self.viewer.camera.angles = (0, 0, 90)\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Set up the viewer for rendering.\"\"\"\n",
    "        self.viewer.window.qt_viewer.canvas.size = self.target_size\n",
    "        self._center_on_canvas()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Reset the viewer after rendering.\"\"\"\n",
    "        self.viewer.window.qt_viewer.canvas.size = self.input_canvas_size\n",
    "        self.viewer.camera.center = self.center\n",
    "        self.viewer.camera.zoom = self.zoom\n",
    "        self.viewer.camera.angles = self.angles\n",
    "\n",
    "def get_choices(gui):\n",
    "    \"\"\"Return the choices for the axis dropdown.\"\"\"\n",
    "    viewer: napari.Viewer\n",
    "    viewer = napari.current_viewer()\n",
    "    choices = []\n",
    "    for i, axis in enumerate(viewer.dims.axis_labels[:-2]):\n",
    "        if axis is not None:\n",
    "            choices.append(i)\n",
    "    return choices\n",
    "\n",
    "@magicgui(call_button=\"export\", directory={\"mode\": \"d\", \"label\": \"Choose a directory\"}, axis={\"choices\": get_choices}, output_type={\"choices\": [\"tif\", \"mp4\"]})\n",
    "def render_as_rgb(viewer: napari.Viewer, axis: Optional[int], directory=Path(), name: str = \"out\",  output_type = \"mp4\", fps: int = 12, upsample_factor: int = 1):\n",
    "    \"\"\"Render the viewer for a single timepoint.\"\"\"\n",
    "    axis = int(axis) if axis is not None else None\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        with CameraSetter(viewer, upsample_factor):\n",
    "            if axis is not None:\n",
    "                rgb = []\n",
    "                for i in range(viewer.dims.range[axis][1].astype(int)):\n",
    "                    viewer.dims.set_current_step(axis, i)\n",
    "                    rendered_img = viewer.window.qt_viewer.canvas.render(alpha=False)\n",
    "                    rgb.append(rendered_img)\n",
    "                rendered_img = np.stack(rgb)\n",
    "            else:\n",
    "                rendered_img = viewer.window.qt_viewer.canvas.render(alpha=False)\n",
    "\n",
    "    outpath = directory.joinpath(f\"{name}.{output_type}\").as_posix()\n",
    "    if output_type == \"tif\":\n",
    "        io.imsave(outpath, rendered_img)\n",
    "    elif output_type == \"mp4\":\n",
    "        if axis is None:\n",
    "            raise ValueError(\"You must specify an axis to export as mp4\")\n",
    "        try:\n",
    "            import cv2\n",
    "        except ImportError:\n",
    "            raise ImportError(\"You must install opencv to export as mp4, try `pip install opencv-python`\")\n",
    "\n",
    "        # Read the first image to get the width, height\n",
    "        frame = rendered_img[0]\n",
    "        h, w, layers = frame.shape\n",
    "\n",
    "        # Define the codec and create a VideoWriter object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        out = cv2.VideoWriter(outpath, fourcc, fps, (w, h))\n",
    "\n",
    "        for image in rendered_img:\n",
    "            out.write(cv2.cvtColor(image, cv2.COLOR_RGBA2BGR))  # Write out frame to video\n",
    "\n",
    "        # Release everything when the job is finished\n",
    "        out.release()\n",
    "        try:\n",
    "            cv2.destroyAllWindows()\n",
    "        except:\n",
    "            print(\"could not close cv2 windows\")\n",
    "\n",
    "\n",
    "if globals().get(\"viewer\") is None:\n",
    "    viewer = napari.Viewer()\n",
    "else:\n",
    "    viewer = globals()[\"viewer\"]\n",
    "\n",
    "viewer.window.add_dock_widget(render_as_rgb, name=\"render as rgb\")\n",
    "viewer.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T13:36:03.208120Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
